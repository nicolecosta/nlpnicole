{"title": "Ryan Hoque", "content": "Ryan Hoque I am a third year PhD candidate in the UC Berkeley EECS department working on Robotics and Artificial Intelligence. I am advised by Ken Goldberg and am part of the Berkeley Artificial Intelligence Research (BAIR) lab.               I have also collaborated with Pieter Abbeel and folks from Google Brain, Meta AI, Honda Research Institute, and  Uber ATG (acq. Aurora). My research primarily focuses on algorithms for robot fleet learning from interactive human supervision. Email \u00a0/\u00a0                CV \u00a0/\u00a0                Google Scholar \u00a0/\u00a0                Github \u00a0/\u00a0                LinkedIn \u00a0/\u00a0                Twitter                 My PhD research is focused on the development of interactive imitation and reinforcement learning algorithms that scale to large robot fleets performing complex tasks (e.g., manipulation). In my undergraduate and Master's research, I worked on learning algorithms for robotic manipulation of deformable objects. In addition to selected publications below                 (see my CV for the full list), check out:                We introduce new formalism, algorithms, and open-source benchmarks for \"Interactive Fleet Learning\": interactive learning with multiple robots and multiple humans.  A novel interactive imitation learning algorithm that reasons about both state novelty and risk to actively query for human interventions more efficiently than prior algorithms.   We propose \"context switching\" between human and robot control as a measure of supervisor burden in interactive imitation learning, and propose an algorithm that reduces context switching during training and execution.  (In collaboration with Robotics at Google) We perform the first systematic benchmarking of fabric manipulation algorithms with Google Reach, a prototype hardware testbed for low-latency remote robot control over the Internet.   (In collaboration with Honda Research Institute) Journal paper extending the VSF conference paper below with new datasets, visual dynamics models, cost functions, optimizers, and physical experiments.  (In collaboration with Honda Research Institute) A novel model-based reinforcement learning technique that trains a visual dynamics model for sequentially manipulating fabric toward a variety of goal images, entirely from random interaction RGBD data in simulation.                 I'm a Bay Area native and a lifelong bear: I earned my B.S. and M.S. in EECS at UC Berkeley and am still here for my PhD. Outside of research, I enjoy an eclectic mix of hobbies including playing the piano and ukulele, reading and writing about philosophy (especially metaphysics), and the outdoors. Some fun facts you may find interesting:                             Website template from BAIR alum  Jon Barron. This template seems to be quite popular!              ", "url": "https://ryanhoque.github.io", "threshold": -0.8940354586768677}