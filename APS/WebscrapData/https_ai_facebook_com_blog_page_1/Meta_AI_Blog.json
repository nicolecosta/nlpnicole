{"title": "Meta AI Blog", "content": "ImageBind is the first AI model capable of binding information from six modalities. May 09, 2023 ImageBind is the first AI model capable of binding information from six modalities. May 09, 2023 Today, we are open-sourcing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results that match or surpass the standard approach used in the field. April 17, 2023 Introducing a dataset and demo code to animate original artwork April 13, 2023 Blog April 25, 2023 Meta AI has released a new \u201cCookbook of Self-Supervised Learning,\" which provides AI researchers and practitioners with a practical guide on how to navigate SSL methods. This is part of our efforts to lower the barrier and help democratize access to SSL research. April 25, 2023  Blog April 17, 2023 Today, we are open-sourcing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results that match or surpass the standard approach used in the field. April 17, 2023  Blog April 13, 2023 With this dataset and animation code, we believe that the domain of amateur drawings can inspire a new generation of creators with its expressive and accessible possibilities. April 13, 2023  Blog April 05, 2023 We're releasing the Segment Anything Model (SAM) \u2014 a step toward the first foundation model for image segmentation \u2014 and the SA-1B dataset. April 05, 2023  Blog March 31, 2023 Training robots in the wild is slow, expensive, and dangerous. FAIR has developed an artificial visual cortex (VC-1) from egocentric videos and visuomotor skills from simulated environments that can form the foundation for embodied intelligence. VC-1 achieves impressive results on 17 different sensorimotor tasks in virtual environments, and the visuomotor skills deployed on the Spot robot achieve near-perfect performance on the task of navigating and fetching objects in indoor environments. March 31, 2023  Blog March 24, 2023 AI development ecosystems are increasingly complex and challenging to maintain. We're sharing details on our work to develop highly efficient systems to build, serve and improve AI models for production uses. March 24, 2023  Blog March 09, 2023 We created Casual Conversations v2, a consent-driven dataset of recorded monologues that includes ten self-provided and annotated categories which will enable researchers to evaluate fairness and robustness of AI models. March 09, 2023  Blog March 08, 2023 Introducing MuAViC \u2014 A new benchmark for audio-visual learning for robust speech translation. We used it to train model to translate speech in noisy, challenging settings, achieving results outperforming other leading translation models. March 08, 2023  Blog February 24, 2023 Today, we\u2019re releasing our LLaMA (Large Language Model Meta AI) foundational model with a gated release. LLaMA is more efficient and competitive with previously published models of a similar size on existing benchmarks. February 24, 2023  Blog January 11, 2023 Today, we\u2019re sharing an update on the Responsible AI progress we made in 2022. January 11, 2023  Blog December 20, 2022 Conversational summarization could be particularly useful for augmented and virtual reality devices, where the screen space is small and the need for concise information is high. December 20, 2022  Blog December 13, 2022 We created data2vec 2.0, a general self-supervised AI algorithm for speech, vision, and text that can train models 16x faster than the most popular existing algorithm for images while achieving the same accuracy. December 13, 2022  Who We Are Latest Work Our Actions Newsletter  Meta \u00a9 2023", "url": "https://ai.facebook.com/blog/", "threshold": 0.9995339405346724}