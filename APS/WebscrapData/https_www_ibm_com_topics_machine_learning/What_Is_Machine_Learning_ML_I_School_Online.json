{"title": "What Is Machine Learning (ML)? - I School Online", "content": "Home  June 26, 2020\u00a0 Most of us would find it hard to go a full day without using at least one app or web service driven by machine learning. But what is machine learning (ML), exactly? Though the term machine learning has become increasingly common, many people still don\u2019t know exactly what it means and how it is applied, nor do they understand the role of machine learning algorithms and datasets in data science. Here, we will examine the question \u201cwhat is ML?\u201d We will provide insight into how machine learning is used by data scientists and others, how it was developed, and what lies ahead as it continues to evolve.\u00a0 The basic concept of machine learning in data science involves using statistical learning and optimization methods that let computers analyze datasets and identify patterns (view a visual of machine learning via R2D3). Machine learning techniques leverage data mining to identify historic trends and inform future models. The typical supervised machine learning algorithm consists of roughly three components: For example, if you\u2019re building a movie recommendation system, you can provide information about yourself and your watch history as input. The algorithm will take that input and learn how to return an accurate output: movies you will enjoy. Some inputs could be movies you watched and rated highly, the percentage of movies you\u2019ve seen that are comedies, or how many movies feature a particular actor. The algorithm\u2019s job is to find these parameters and assign weights to them. If the algorithm gets it right, the weights it used stay the same. If it gets a movie wrong, the weights that led to the wrong decision get turned down so it doesn\u2019t make that kind of mistake again. Since a machine learning algorithm updates autonomously, the analytical accuracy improves with each run as it teaches itself from the data it analyzes. This iterative nature of learning is both unique and valuable because it occurs without human intervention \u2014 empowering the algorithm to uncover hidden insights without being specifically programmed to do so.\u00a0 There are many types of machine learning models defined by the presence or absence of human influence on raw data \u2014 whether a reward is offered, specific feedback is given, or labels are used. According to Nvidia.com, there are different machine learning models such as: Finally, there\u2019s the concept of deep learning, which is a newer area of machine learning that automatically learns from datasets without introducing human rules or knowledge. This requires massive amounts of raw data for processing \u2014 and the more data that is received, the more the predictive model improves. The purpose of machine learning is to use machine learning algorithms to analyze data. By leveraging machine learning, a developer can improve the efficiency of a task involving large quantities of data without the need for manual human input. Around the world, strong machine learning algorithms can be used to improve the productivity of professionals working in data science, computer science, and many other fields. There are a number of machine learning algorithms that are commonly used by modern technology companies. Each of these machine learning algorithms can have numerous applications in a variety of educational and business settings.\u00a0 Read on to learn about many different machine learning algorithms, as well as how they are applicable to the broader field of machine learning. Linear regression is an algorithm used to analyze the relationship between independent input variables and at least one target variable. This kind of regression is used to predict continuous outcomes \u2014 variables that can take any numerical outcome. For example, given data on the neighborhood and property, can a model predict the sale value of a home? Linear relationships occur when the data relationship being observed tends to follow a straight line overall \u2014 and as such, this model can be used to observe whether a data point is increasing, decreasing, or remaining the same relative to some independent variable, such as time elapsed or position. Machine learning models can be employed to analyze data in order to observe and map linear regressions. Independent variables and target variables can be input into a linear regression machine learning model, and the model will then map the coefficients of the best fit line to the data. In other words, the linear regression models attempt to map a straight line, or a linear relationship, through the dataset. Logistic regression is a supervised learning algorithm that is used for classification problems. Instead of continuous output like in linear regression, a logistic model predicts the probability of a binary event occurring. For example, given an email, can a model predict whether the contents are spam or not?\u00a0 Machine learning algorithms can use logistic regression models to determine categorical outcomes. When given a dataset, the logistic regression model can check any weights and biases and then use the given dependent categorical target variables to understand how to correctly categorize that dataset.\u00a0 Neural networks are artificial intelligence algorithms that attempt to replicate the way the human brain processes information to understand and intelligently classify data. These neural network learning algorithms are used to recognize patterns in data and speech, translate languages, make financial predictions, and much more through thousands, or sometimes millions, of interconnected processing nodes. Data is \u201cfed-forward\u201d through layers that process and assign weights, before being sent to the next layer of nodes, and so on. Crucially, neural network algorithms are designed to quickly learn from input training data in order to improve the proficiency and efficiency of the network\u2019s algorithms. As such, neural networks serve as key examples of the power and potential of machine learning models.\u00a0 Decision trees are data structures with nodes that are used to test against some input data. The input data is tested against the leaf nodes down the tree to attempt to produce the correct, desired output. They are easy to visually understand due to their tree-like structure and can be designed to categorize data based on some categorization schema. Decision trees are one method of supervised learning, a field in machine learning that refers to how the predictive machine learning model is devised via the training of a learning algorithm.\u00a0 Random forest models are capable of classifying data using a variety of decision tree models all at once. Like decision trees, random forests can be used to determine the classification of categorical variables or the regression of continuous variables. These random forest models generate a number of decision trees as specified by the user, forming what is known as an ensemble. Each tree then makes its own prediction based on some input data, and the random forest machine learning algorithm then makes a prediction by combining the predictions of each decision tree in the ensemble.\u00a0 Deep learning models are a nascent subset of machine learning paradigms. Deep learning uses a series of connected layers which together are capable of quickly and efficiently learning complex prediction models.\u00a0 If deep learning sounds similar to neural networks, that\u2019s because deep learning is, in fact, a subset of neural networks. Both try to simulate the way the human brain functions. Deep learning models can be distinguished from other neural networks because deep learning models employ more than one hidden layer between the input and the output. This enables deep learning models to be sophisticated in the speed and capability of their predictions.\u00a0 Deep learning models are employed in a variety of applications and services related to artificial intelligence to improve levels of automation in previously manual tasks. You might find this emerging approach to machine learning powering digital assistants like Siri and voice-driven TV remotes, in fraud detection technology for credit card companies, and as the bedrock of operating systems for self-driving cars. Trying to make sense of the distinctions between machine learning vs. AI can be tricky, since the two are closely related. In fact, machine learning algorithms are a subset of artificial intelligence algorithms \u2014 but not the other way around.\u00a0 To pinpoint the difference between machine learning and artificial intelligence, it\u2019s important to understand what each subject encompasses. AI refers to any of the software and processes that are designed to mimic the way humans think and process information. It includes computer vision, natural language processing, robotics, autonomous vehicle operating systems, and of course, machine learning. With the help of artificial intelligence, devices are able to learn and identify information in order to solve problems and offer key insights into various domains. On the other hand, machine learning specifically refers to teaching devices to learn information given to a dataset without manual human interference. This approach to artificial intelligence uses machine learning algorithms that are able to learn from data over time in order to improve the accuracy and efficiency of the overall machine learning model. There are numerous approaches to machine learning, including the previously mentioned deep learning model. Machine learning and data mining, a component of machine learning, are crucial tools used by many companies and researchers. There are two main reasons for this: Companies leveraging algorithms to sort through data and optimize business operations aren\u2019t new. Leveraging algorithms extends not only to digital business models such as web services or apps, but also to any company or industry where data can be gathered, including the following: Amazon, Facebook, Netflix, and, of course, Google have all been using machine learning algorithms to drive searches, recommendations, targeted advertising, and more for well over a decade. For example, Uber Eats shared in a GeekWire article that they use data mining and machine learning to estimate delivery times.\u00a0 Although advances in computing technologies have made machine learning more popular than ever, it\u2019s not a new concept. According to Forbes, the origins of machine learning date back to 1950. Speculating on how one could tell if they had developed a truly integrated artificial intelligence (AI), Alan Turing created what is now referred to as the Turing test, which suggests that one way of testing whether or not the AI is capable of understanding language is to see if it\u2019s able to fool a human into thinking they are speaking to another person. In 1952, Arthur Samuel wrote the first learning program for IBM, this time involving a game of checkers. The work of many other machine learning pioneers followed, including Frank Rosenblatt\u2019s design of the first neural network in 1957 and Gerald DeJong\u2019s introduction of explanation-based learning in 1981. In the 1990s, a major shift occurred in machine learning when the focus moved away from a knowledge-based approach to one driven by data. This was a critical decade in the field\u2019s evolution, as scientists began creating computer programs that could analyze large datasets and learn in the process. The 2000s were marked by unsupervised learning becoming widespread, eventually leading to the advent of deep learning and the ubiquity of machine learning as a practice. Milestones in machine learning are marked by instances in which an algorithm is able to beat the performance of a human being, including Russian chess grandmaster Garry Kasparov\u2019s defeat at the hands of IBM supercomputer Deep Blue in 1997 and, more recently, the 2016 victory of the Google DeepMind AI program AlphaGo over Lee Sedol playing Go, a game notorious for its massively large space of possibilities in game play. Today, researchers are hard at work to expand on these achievements. As machine learning and artificial intelligence applications become more popular, they\u2019re also becoming more accessible, moving from server-based systems to the cloud. At Google Next 2018, Google touted several new deep learning and machine learning capabilities, like Cloud AutoML, BigQuery ML, and more. During the past few years, Amazon, Microsoft, Baidu, and IBM have all unveiled machine learning platforms through open source projects and enterprise cloud services. Machine learning algorithms are here to stay, and they\u2019re rapidly widening the parameters of what research and industry can accomplish. Machine learning algorithms are being used around the world in nearly every major sector, including business, government, finance, agriculture, transportation, cybersecurity, and marketing. Such rapid adoption across disparate industries is evidence of the value that machine learning (and, by extension, data science) creates. Armed with insights from vast datasets \u2014 which often occur in real time \u2014 organizations can operate more efficiently and gain a competitive edge. The applications of machine learning and artificial intelligence extend beyond commerce and optimizing operations. Following its Jeopardy win, IBM applied the Watson algorithm to medical research literature, thereby \u201csending Watson to medical school.\u201d More recently, precision medicine initiatives are breaking new ground using machine learning algorithms driven by massive artificial neural networks (i.e., \u201cdeep learning\u201d algorithms) to detect subtle patterns in genetic structure and how one might respond to different medical treatments. Breakthroughs in how machine learning algorithms can be used to represent natural language have enabled a surge in new possibilities that include automated text translation, text summarization techniques, and sophisticated question and answering systems. Other advancements involve learning systems for automated robotics, self-flying drones, and the promise of industrialized self-driving cars. The continued digitization of most sectors of society and industry means that an ever-growing volume of data will continue to be generated. The ability to gain insights from these vast datasets is one key to addressing an enormous array of issues \u2014 from identifying and treating diseases more effectively, to fighting cyber criminals, to helping organizations operate more effectively to boost the bottom line. The universal capabilities that machine learning enables across so many sectors make it an essential tool \u2014 and experts predict a bright future for its use. In fact, in Gartner\u2019s \u201cTop 10 Technology Trends for 2017,\u201d machine learning and artificial intelligence topped the list: \u201cAI and machine learning [\u2026] can also encompass more advanced systems that understand, learn, predict, adapt and potentially operate autonomously.\u201d The article also notes: \u201cThe combination of extensive parallel processing power, advanced algorithms and massive datasets to feed the algorithms has unleashed this new era.\u201d In recognition of machine learning\u2019s critical role today and in the future, datascience@berkeley includes an in-depth focus on machine learning in its online Master of Information and Data Science (MIDS) curriculum. The foundation course is Applied Machine Learning, which provides a broad introduction to the key ideas in machine learning. The emphasis is on intuition and practical examples rather than theoretical results, though some experience with probability, statistics, and linear algebra is important. Students learn how to apply powerful machine learning techniques to new problems, run evaluations and interpret results, and think about scaling up from thousands of data points to billions. The advanced course, Machine Learning at Scale, builds on and goes beyond the collect-and-analyze phase of big data by focusing on how machine learning algorithms can be rewritten and extended to scale to work on petabytes of data, both structured and unstructured, to generate sophisticated models used for real-time predictions. In the Natural Language Processing with Deep Learning course, students learn how-to skills using cutting-edge distributed computation and machine learning systems such as Spark. They are trained to code their own implementations of large-scale projects, like Google\u2019s original PageRank algorithm, and discover how to use modern deep learning techniques to train text-understanding algorithms. Learn more about the datascience@berkeley curriculum or explore the online Machine Learning short course from the UC Berkeley School of Information, which requires no programming or coding experience, and prepares working professionals to implement machine learning in their organization. Citation for this content: datascience@berkeley, the online Master of Information and Data Science from UC Berkeley. Last updated February 2022.  ", "url": "https://ischoolonline.berkeley.edu/blog/what-is-machine-learning/", "threshold": -0.9999999986640933}