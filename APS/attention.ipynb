{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.utils import text_dataset_from_directory\n",
    "import codecs\n",
    "import tempfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, TimeDistributed, Softmax, TextVectorization, Reshape, RepeatVector, Conv1D, Bidirectional, AveragePooling1D, UpSampling1D, Embedding, Concatenate, GlobalAveragePooling1D, LSTM, Multiply, MultiHeadAttention\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = r'./WebscrapData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the content data\n",
    "content_list = []\n",
    "\n",
    "# Iterate over the folders in the root directory\n",
    "for folder_name in os.listdir(DATASET_DIR):\n",
    "    folder_path = os.path.join(DATASET_DIR, folder_name)\n",
    "    \n",
    "    # Check if the item in the root directory is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Iterate over the JSON files in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.json'):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                \n",
    "                # Read the JSON file\n",
    "                with open(file_path, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "                \n",
    "                # Access the content component or any other data within the JSON\n",
    "                content = data['content']  # Replace 'content' with the actual key in your JSON\n",
    "                \n",
    "                # Append the content to the list\n",
    "                content_list.append(content)\n",
    "\n",
    "# Create a DataFrame from the content list\n",
    "df = pd.DataFrame({'content': content_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Because we can’t truly advance groundbreaking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>December 20, 2022  Summarization using automat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>April 13, 2023  From a young age, people expre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December 13, 2022  Many recent breakthroughs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>April 17, 2023 Ocorreu um erroEstamos tendo pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Adam Geitgey Follow -- 72 Listen Share Update:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Adam Geitgey Follow -- 27 Listen Share Update:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Adam Geitgey Follow -- 18 Listen Share This ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Adam Geitgey Follow -- 263 Listen Share Update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Your Custom Text Here Machine Learning is Fun!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>549 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content\n",
       "0    Because we can’t truly advance groundbreaking ...\n",
       "1    December 20, 2022  Summarization using automat...\n",
       "2    April 13, 2023  From a young age, people expre...\n",
       "3    December 13, 2022  Many recent breakthroughs i...\n",
       "4    April 17, 2023 Ocorreu um erroEstamos tendo pr...\n",
       "..                                                 ...\n",
       "544  Adam Geitgey Follow -- 72 Listen Share Update:...\n",
       "545  Adam Geitgey Follow -- 27 Listen Share Update:...\n",
       "546  Adam Geitgey Follow -- 18 Listen Share This ar...\n",
       "547  Adam Geitgey Follow -- 263 Listen Share Update...\n",
       "548  Your Custom Text Here Machine Learning is Fun!...\n",
       "\n",
       "[549 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(df['content'].values)\n",
    "\n",
    "# Batch the dataset\n",
    "batch_size = 16\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, TextVectorization\n",
    "from keras.models import Model\n",
    "vocab_size = 1000\n",
    "seq_len = 10\n",
    "vectorize_layer = TextVectorization(max_tokens=vocab_size, output_sequence_length=seq_len)\n",
    "vectorize_layer.adapt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 9, 32)        32000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 9, 32)       818         ['embedding[0][0]',              \n",
      " dAttention)                                                      'embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 1)            136         ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 1)            136         ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2)            0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1000)         3000        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 1000)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,090\n",
      "Trainable params: 36,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def predict_word(seq_len, latent_dim, vocab_size):\n",
    "\n",
    "    # define imput layer\n",
    "    input_layer = Input(shape=(seq_len-1,))\n",
    "    x = input_layer\n",
    "\n",
    "    # add embedding layer\n",
    "    x = Embedding(vocab_size, latent_dim, name='embedding', mask_zero=True)(x)\n",
    "\n",
    "    # apply attention\n",
    "    x = MultiHeadAttention(num_heads=3, key_dim=2)(x, value=x)\n",
    "\n",
    "    # apply bidirectional LSTM\n",
    "    x1 = LSTM(1)(x)\n",
    "    x2 = LSTM(1, go_backwards=True)(x)\n",
    "\n",
    "    # concatenate LSTM outputs\n",
    "    x = Concatenate()([x1, x2])\n",
    "    latent_rep = x\n",
    "\n",
    "    # add final dense and softmax layers\n",
    "    x = Dense(vocab_size)(x)\n",
    "    x = Softmax()(x)\n",
    "\n",
    "    # create and return model\n",
    "    return Model(input_layer, x), Model(input_layer, latent_rep)\n",
    "\n",
    "# create predictor and latent model\n",
    "predictor, latent = predict_word(10, 32, vocab_size)\n",
    "\n",
    "# print model summary\n",
    "predictor.summary()\n",
    "\n",
    "# configure optimizer and loss function\n",
    "#opt = keras.optimizers.SGD(learning_rate=1, momentum=0.9)\n",
    "opt = keras.optimizers.Nadam(learning_rate=0.1)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "    ignore_class=1,\n",
    "    name=\"sparse_categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "#compile the model\n",
    "predictor.compile(loss=loss_fn, optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_ultimo_token(x):\n",
    "    x_ = vectorize_layer(x)\n",
    "    x_ = x_[:,:-1]\n",
    "    y_ = x_[:,-1:]\n",
    "    return x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(None, 9), dtype=tf.int64, name=None), TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(separar_ultimo_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EarlyStopping callback\n",
    "# Configure early stopping callback\n",
    "early_stopping = EarlyStopping(patience=5, restore_best_weights=True, monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "35/35 [==============================] - 14s 19ms/step - loss: 5.8131 - accuracy: 0.1275\n",
      "Epoch 2/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 4.2131 - accuracy: 0.1220\n",
      "Epoch 3/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.8581 - accuracy: 0.1166\n",
      "Epoch 4/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.9464 - accuracy: 0.1275\n",
      "Epoch 5/60\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 3.6887 - accuracy: 0.1457\n",
      "Epoch 6/60\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 3.5373 - accuracy: 0.1457\n",
      "Epoch 7/60\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 3.4446 - accuracy: 0.1530\n",
      "Epoch 8/60\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 3.3802 - accuracy: 0.1512\n",
      "Epoch 9/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.3333 - accuracy: 0.1512\n",
      "Epoch 10/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.2979 - accuracy: 0.1494\n",
      "Epoch 11/60\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 3.2705 - accuracy: 0.1512\n",
      "Epoch 12/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.2487 - accuracy: 0.1512\n",
      "Epoch 13/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.2309 - accuracy: 0.1530\n",
      "Epoch 14/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.2162 - accuracy: 0.1530\n",
      "Epoch 15/60\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 3.2037 - accuracy: 0.1530\n",
      "Epoch 16/60\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 3.1930 - accuracy: 0.1512\n",
      "Epoch 17/60\n",
      "35/35 [==============================] - 1s 18ms/step - loss: 3.1838 - accuracy: 0.1512\n",
      "Epoch 18/60\n",
      "35/35 [==============================] - 1s 22ms/step - loss: 3.1757 - accuracy: 0.1512\n",
      "Epoch 19/60\n",
      "35/35 [==============================] - 1s 23ms/step - loss: 3.1686 - accuracy: 0.1512\n",
      "Epoch 20/60\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 3.1622 - accuracy: 0.1512\n",
      "Epoch 21/60\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 3.1565 - accuracy: 0.1566\n",
      "Epoch 22/60\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 3.1513 - accuracy: 0.1566\n",
      "Epoch 23/60\n",
      "35/35 [==============================] - 1s 21ms/step - loss: 3.1466 - accuracy: 0.1566\n",
      "Epoch 24/60\n",
      "35/35 [==============================] - 1s 20ms/step - loss: 3.1423 - accuracy: 0.1566\n",
      "Epoch 25/60\n",
      "35/35 [==============================] - 1s 19ms/step - loss: 3.1384 - accuracy: 0.1566\n",
      "Epoch 26/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1347 - accuracy: 0.1566\n",
      "Epoch 27/60\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 3.1313 - accuracy: 0.1566\n",
      "Epoch 28/60\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 3.1281 - accuracy: 0.1585\n",
      "Epoch 29/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1251 - accuracy: 0.1585\n",
      "Epoch 30/60\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 3.1224 - accuracy: 0.1585\n",
      "Epoch 31/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.1198 - accuracy: 0.1585\n",
      "Epoch 32/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.1173 - accuracy: 0.1585\n",
      "Epoch 33/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.1150 - accuracy: 0.1585\n",
      "Epoch 34/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.1128 - accuracy: 0.1585\n",
      "Epoch 35/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1107 - accuracy: 0.1585\n",
      "Epoch 36/60\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 3.1088 - accuracy: 0.1585\n",
      "Epoch 37/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1069 - accuracy: 0.1585\n",
      "Epoch 38/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.1051 - accuracy: 0.1585\n",
      "Epoch 39/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1034 - accuracy: 0.1585\n",
      "Epoch 40/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.1018 - accuracy: 0.1585\n",
      "Epoch 41/60\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 3.1003 - accuracy: 0.1585\n",
      "Epoch 42/60\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 3.0988 - accuracy: 0.1585\n",
      "Epoch 43/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.0974 - accuracy: 0.1585\n",
      "Epoch 44/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.0960 - accuracy: 0.1585\n",
      "Epoch 45/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.0947 - accuracy: 0.1548\n",
      "Epoch 46/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.0934 - accuracy: 0.1548\n",
      "Epoch 47/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.0922 - accuracy: 0.1548\n",
      "Epoch 48/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.0910 - accuracy: 0.1548\n",
      "Epoch 49/60\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 3.0899 - accuracy: 0.1530\n",
      "Epoch 50/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.0888 - accuracy: 0.1530\n",
      "Epoch 51/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.0877 - accuracy: 0.1530\n",
      "Epoch 52/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.0867 - accuracy: 0.1530\n",
      "Epoch 53/60\n",
      "35/35 [==============================] - 1s 30ms/step - loss: 3.0857 - accuracy: 0.1530\n",
      "Epoch 54/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.0848 - accuracy: 0.1530\n",
      "Epoch 55/60\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 3.0838 - accuracy: 0.1530\n",
      "Epoch 56/60\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 3.0829 - accuracy: 0.1530\n",
      "Epoch 57/60\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 3.0820 - accuracy: 0.1530\n",
      "Epoch 58/60\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 3.0812 - accuracy: 0.1530\n",
      "Epoch 59/60\n",
      "35/35 [==============================] - 1s 31ms/step - loss: 3.0803 - accuracy: 0.1530\n",
      "Epoch 60/60\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 3.0795 - accuracy: 0.1530\n"
     ]
    }
   ],
   "source": [
    "history = predictor.fit(dataset.map(separar_ultimo_token), epochs=60, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n",
      "tools\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "article\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "for\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "models\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "with\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "life\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "using\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "about\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "so\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "in\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'machine learning is tools article for models with life using about so in'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predizer2(entrada, numero_de_predicoes, modelo, vectorize_layer, temperature=0):\n",
    "    frase = entrada\n",
    "    contexto = frase # Contexto deslizante\n",
    "    temperature = temperature\n",
    "\n",
    "    for n in range(numero_de_predicoes):\n",
    "        pred = modelo.predict(vectorize_layer([contexto])[:,:-1])\n",
    "\n",
    "        # Nao repetir palavras\n",
    "        tentando = True\n",
    "        while tentando:\n",
    "\n",
    "            # Selectionar de k-best\n",
    "            candidatos = tf.math.top_k(pred, k=10).indices[0,:]\n",
    "            idx = np.random.choice(candidatos.numpy())\n",
    "            # idx = tf.argmax(pred, axis=1)[0]\n",
    "            word = vectorize_layer.get_vocabulary()[idx]\n",
    "            if word in frase.split():\n",
    "                pred[0][idx] = 0\n",
    "            else:\n",
    "                tentando = False\n",
    "                \n",
    "        frase = frase + \" \" + word\n",
    "        contexto = contexto + \" \" + word\n",
    "        #print(frase)\n",
    "        contexto = ' '.join(frase.split()[1:])\n",
    "        print(word)\n",
    "    return frase\n",
    "\n",
    "predizer2(\"machine learning is\", 10, predictor, vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
